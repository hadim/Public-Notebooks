{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find connections within your field of research papers\n",
    "\n",
    "The idea is to retrieve Mendeley documents from my personal database and then process it to show connections between authors into my bibliography.\n",
    "\n",
    "I used NetworkX but a better alternative (but more complex) is to use https://graph-tool.skewed.de/.\n",
    "\n",
    "At the end of the process, I export my graph into a GraphML file so I can open it with Cytoscape designed to perform complex visual data analysis (http://www.cytoscape.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from mendeley import Mendeley\n",
    "from requests_oauthlib import OAuth2Session\n",
    "from mendeley.session import MendeleySession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Put your **client ID** in **client secret** here. You can generate them from http://dev.mendeley.com/myapps.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_id = \"1821\"\n",
    "client_secret = \"4GgB5kDWz33Z6ggv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get authors data from Mendeley API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please go to https://api.mendeley.com/oauth/authorize?response_type=code&client_id=1821&redirect_uri=https%3A%2F%2Flocalhost&scope=all&state=I3IqA7PNhVnr4uO67VZOayY15WKcaP&approval_prompt=force&access_type=offline and authorize access.\n"
     ]
    }
   ],
   "source": [
    "redirect_uri = 'https://localhost'\n",
    "\n",
    "authorization_base_url = \"https://api.mendeley.com/oauth/authorize\"\n",
    "token_url = \"https://api.mendeley.com/oauth/token\"\n",
    "\n",
    "scope = ['all']\n",
    "\n",
    "oauth = OAuth2Session(client_id, redirect_uri=redirect_uri, scope=scope)\n",
    "\n",
    "authorization_url, state = oauth.authorization_url(authorization_base_url,\n",
    "                                                   access_type=\"offline\",\n",
    "                                                   approval_prompt=\"force\")\n",
    "\n",
    "print('Please go to {} and authorize access.'.format(authorization_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paste the fallback url here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "authorization_code = \"https://localhost/?code=gwBv7x-wAp8t7IXCKrD4ADX3zIE&state=I3IqA7PNhVnr4uO67VZOayY15WKcaP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create MendeleySession object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token = oauth.fetch_token(token_url, authorization_response=authorization_code, client_secret=client_secret)\n",
    "\n",
    "mendeley = Mendeley(client_id, client_secret, redirect_uri=redirect_uri)\n",
    "session = MendeleySession(mendeley, token=token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define on which document you want to work\n",
    "\n",
    "You may want to define a different `get_documents()` to work only on a subset of documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return all documents from personal Mendeley database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_documents():\n",
    "    return session.documents.iter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usefull functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "similarity_score = 0.7\n",
    "\n",
    "def match(a1, a2):\n",
    "    return SequenceMatcher(None, a1, a2).ratio()\n",
    "\n",
    "def get_id(name):\n",
    "    if data.empty:\n",
    "        return 0\n",
    "\n",
    "    # Find similar name and put the same author_id if it exists\n",
    "    similar = data[data.apply(lambda x: match(name, x['full_name']) > similarity_score, axis=1)]\n",
    "    \n",
    "    if not similar.empty:\n",
    "        return similar['author_id'].iloc[0]\n",
    "    else:\n",
    "        return data['author_id'].max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate over the documents\n",
    "\n",
    "Data are saved to a Pandas.DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................................................................................................................."
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for doc in get_documents():\n",
    "    print(\".\", end='')\n",
    "    \n",
    "    if doc.authors:\n",
    "        n_authors = len(doc.authors)\n",
    "\n",
    "        for i, author in enumerate(doc.authors):\n",
    "            d = {}\n",
    "            d['first_name'] = author.first_name\n",
    "            d['last_name'] = author.last_name\n",
    "            d['full_name'] = author.first_name + \" \" + author.last_name\n",
    "            d['title'] = doc.title\n",
    "            d['article_id'] = doc.id\n",
    "            d['article_keywords'] = doc.keywords if doc.keywords else []\n",
    "            d['article_year'] = doc.year\n",
    "            d['author_position'] = i + 1\n",
    "            d['authors_numbers'] = n_authors\n",
    "            d['author_id'] = get_id(d['full_name'])\n",
    "            \n",
    "            data = data.append(pd.Series(d), ignore_index=True)\n",
    "            \n",
    "raw_data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data\n",
    "\n",
    "\n",
    "Create a graph with NetworkX where each node is an author and weight between two authors is the number of common articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph(data):\n",
    "    \n",
    "    # Relabel from zero (take A LOT OF TIME)\n",
    "    # Optimization are welcome !\n",
    "    for i, old_i in enumerate(data['author_id'].unique()):\n",
    "        data.loc[:, 'author_id'][data['author_id'] == old_i] = i\n",
    "        \n",
    "    # Generate adjacency matrix\n",
    "    N = data['author_id'].max() + 1\n",
    "\n",
    "    adj_mat = np.zeros((N, N))\n",
    "\n",
    "    for (i1, a1), (i2, a2) in itertools.combinations(data.iterrows(), 2):\n",
    "        if a1['article_id'] == a2['article_id']:\n",
    "            adj_mat[a1['author_id'], a2['author_id']] += 1\n",
    "            adj_mat[a2['author_id'], a1['author_id']] += 1\n",
    "\n",
    "    # Create NetworkX graph\n",
    "    g = nx.DiGraph()\n",
    "    g = nx.from_numpy_matrix(adj_mat, create_using=g)\n",
    "\n",
    "    # Add attributes to node\n",
    "    for id_node in g.nodes_iter():\n",
    "        node = g.node[id_node]\n",
    "        node['full_name'] = data[data['author_id'] == id_node].iloc[0][\"full_name\"]\n",
    "        node['n_article'] = str(len(data[data['author_id'] == id_node]))\n",
    "\n",
    "    # Add attributes to edges\n",
    "    for n1, n2 in g.edges_iter():\n",
    "        edge = g[n1][n2]\n",
    "        edge['common_articles'] = str(adj_mat[n1, n2])\n",
    "    \n",
    "    # Remove authors without common articles\n",
    "    outdeg = g.out_degree()\n",
    "    to_remove = [k for k, v in outdeg.items() if v == 0]\n",
    "    g.remove_nodes_from(to_remove)\n",
    "    \n",
    "    return adj_mat, g\n",
    "\n",
    "def draw(g, font_size=12):\n",
    "    \n",
    "    node_attribute_to_draw = 'full_name'\n",
    "\n",
    "    labels = dict((n, d[node_attribute_to_draw]) for n, d in g.nodes(data=True))\n",
    "    #edge_colors = [g[n1][n2]['common_articles'] for n1, n2 in g.edges()]\n",
    "    \n",
    "    draw_kwargs = dict(node_shape='o', node_color='red',\n",
    "                       alpha=1, font_size=12, linewidths=0,\n",
    "                       width=0.1,)\n",
    "                       #edge_color=edge_colors, edge_cmap=plt.cm.Blues)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    nx.draw_graphviz(g, with_labels=True, labels=labels, node_size=10, ax=ax, **draw_kwargs)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def print_info(data):\n",
    "    print(\"You have {} differents authors in {} different articles\".format(len(data.groupby('author_id')),\n",
    "                                                                           len(data.groupby('article_id'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 619 differents authors in 172 different articles\n"
     ]
    }
   ],
   "source": [
    "data = raw_data.copy()\n",
    "print_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadim/local/conda/envs/st/lib/python3.4/site-packages/IPython/kernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "mat, g = create_graph(data)\n",
    "fig = draw(g, font_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to remove all authors with less than 2 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 136 differents authors in 146 different articles\n"
     ]
    }
   ],
   "source": [
    "data = raw_data.copy()\n",
    "max_article_by_authors = 2\n",
    "\n",
    "articles_by_authors = data.groupby('author_id').size()\n",
    "authors_index = articles_by_authors[articles_by_authors >= max_article_by_authors].index\n",
    "data = data.set_index('author_id').loc[authors_index].reset_index()\n",
    "\n",
    "print_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadim/local/conda/envs/st/lib/python3.4/site-packages/IPython/kernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "mat, g = create_graph(data)\n",
    "fig = draw(g, font_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it as a GraphML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.write_graphml(g, os.path.join(os.environ['HOME'], \"authors.graphml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter to keep only principal investigator (last or before last author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 84 differents authors in 138 different articles\n"
     ]
    }
   ],
   "source": [
    "data = data[data.apply(lambda x: (x['authors_numbers'] - x['author_position']) <= 1, axis=1)]\n",
    "print_info(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hadim/local/conda/envs/st/lib/python3.4/site-packages/IPython/kernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "mat, g = create_graph(data)\n",
    "fig = draw(g, font_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data outside of Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the GraphML file (you can also export to others format, see http://networkx.github.io/documentation/latest/reference/readwrite.html), you can process the graph with others softwares (such as Cytoscape, Tulip, D3.js, etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example with Cytoscape\n",
    "\n",
    "![cytoscape](cytoscape.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
